{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Joel Grus - $\\textit{Machine Learning}$ is creating and using models that have been learned from data.\n",
    " \n",
    " SAS - $\\textit{Machine Learning}$ is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that machines should be able to learn and adapt through experience.\n",
    " \n",
    " ExpertSystem - $\\textit{Machine Learning}$ is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\n",
    " \n",
    " \n",
    "Machine Learning advances the potential of computing and extends human cognition in a very significant way: it allows the creation of programs that do things that the programmer does not understand how to do. For example (from Quora), given the sequence $1,2,4,8,16,32,\\dots$, it is quite easy for a human to determine a rule that predicts each element. But what if the sequence were determined by some outlandishly complex rule, perhaps involving a recursion using $10000$ of the previous entries? Without certain nice properties to the recursion, this would likely be beyond the ability of any human to determine via traditional techniques. However, with machine learning a computer may be able to discover a predictive model.\n",
    " \n",
    " \n",
    "Machine Learning proceeds under at least two distinct types  methods:\n",
    "\n",
    "1. Supervised Learning \n",
    "\n",
    "Supervised Learning is performed on a $\\textit{labelled}$ dataset, that is, one where the correct responses to given input are known, allowing direct comparison to the output of the model. Examples: classification of objects in images against correct labels, estimation of stock market evolution.\n",
    "\n",
    "2. Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, no attempt is made to predict future output. The goal is instead to discover structure to the data. E.g. cluster data points that are proximal in some way, classification where classes did not previously exist. \n",
    "\n",
    "3. Semi-Supervised Learning\n",
    "\n",
    "Here part of the input dataset is labelled, usually only a small number of entries compared with the whole.\n",
    "\n",
    "4. Reinforcement Learning\n",
    "\n",
    "Not really sure how this works. Computer is assigned a task and some kind of reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data, prob):\n",
    "    \"\"\"Split data into two groups, the first with probability prob and second with 1-prob\"\"\"\n",
    "    results = [],[]\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "def train_test_split(x, y, test_pct):\n",
    "    \"\"\"x is a matrix of input variables, y is a vector of oputput variables\"\"\"\n",
    "    data = zip(x,y)\n",
    "    train, test = split_data(data, 1- test_pct)\n",
    "    x_train, y_train = zip(*train)\n",
    "    x_test, y_test = zip(*train)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of separating training an testing data is to prevent over-fitting. Over fitting occurs when an algorithm or formula describes a dataset so closely that noise is integrated with the model. The model should perform poorly in the test set if the data is overfitted. In cases where you want to compare performance between models, you can split your data into 3 sets: training, testing and validation. In this situation, the testing set serves as a second training set and performance on this set is used to determine which model to use. The validation dataset is then used to determine whether your competiting models have overfitted on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981090945453\n",
      "0.014\n",
      "0.00498220640569\n",
      "0.000141967671933\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "\n",
    "def accuracy(tp,fp,fn,tn):\n",
    "    \"\"\"fraction of results that are correct predictions\"\"\"\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "\n",
    "def precision(tp,fp,fn,tn):\n",
    "    \"\"\"Fraction of prediction \"true\" that are correct\"\"\"\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "\n",
    "def recall(tp,fp,fn,tn):\n",
    "    \"\"\"Fraction of all true positives achieved by model\"\"\"\n",
    "    return tp/(tp+fn)\n",
    "\n",
    "def f1_score(tp,fp,fn,tn):\n",
    "    p = precision(tp,fp,tn,fn)\n",
    "    r = recall(tp,fp,tn,fn)\n",
    "    \n",
    "    return 2 * p * r/(p + r)\n",
    "\n",
    "print accuracy(70, 4930, 13980, 981070)\n",
    "print precision(70, 4930, 13980, 981070)\n",
    "print recall(70, 4930, 13980, 981070)\n",
    "print f1_score(70, 4930, 13980, 981070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
